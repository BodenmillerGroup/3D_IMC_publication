{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread, imsave\n",
    "import os, re, sys, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyp\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.measure import regionprops, regionprops_table, label\n",
    "from skimage.segmentation import clear_border\n",
    "import cv2\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy import ndimage as ndi\n",
    "import napari\n",
    "sys.path.append('~/3D_IMC_paper/Python/python_3d_imc_tools')\n",
    "from io_files import image_filepath_for_3D_stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied the function from https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.expand_labels\n",
    "# becuase skimage could not import it for some reason\n",
    "\"\"\"\n",
    "expand_labels is derived from code that was\n",
    "originally part of CellProfiler, code licensed under BSD license.\n",
    "Website: http://www.cellprofiler.org\n",
    "Copyright (c) 2020 Broad Institute\n",
    "All rights reserved.\n",
    "Original authors: CellProfiler team\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "def expand_labels(label_image, distance=1):\n",
    "    \"\"\"Expand labels in label image by ``distance`` pixels without overlapping.\n",
    "    Given a label image, ``expand_labels`` grows label regions (connected components)\n",
    "    outwards by up to ``distance`` pixels without overflowing into neighboring regions.\n",
    "    More specifically, each background pixel that is within Euclidean distance\n",
    "    of <= ``distance`` pixels of a connected component is assigned the label of that\n",
    "    connected component.\n",
    "    Where multiple connected components are within ``distance`` pixels of a background\n",
    "    pixel, the label value of the closest connected component will be assigned (see\n",
    "    Notes for the case of multiple labels at equal distance).\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_image : ndarray of dtype int\n",
    "        label image\n",
    "    distance : float\n",
    "        Euclidean distance in pixels by which to grow the labels. Default is one.\n",
    "    Returns\n",
    "    -------\n",
    "    enlarged_labels : ndarray of dtype int\n",
    "        Labeled array, where all connected regions have been enlarged\n",
    "    Notes\n",
    "    -----\n",
    "    Where labels are spaced more than ``distance`` pixels are apart, this is\n",
    "    equivalent to a morphological dilation with a disc or hyperball of radius ``distance``.\n",
    "    However, in contrast to a morphological dilation, ``expand_labels`` will\n",
    "    not expand a label region into a neighboring region.  \n",
    "    This implementation of ``expand_labels`` is derived from CellProfiler [1]_, where\n",
    "    it is known as module \"IdentifySecondaryObjects (Distance-N)\" [2]_.\n",
    "    There is an important edge case when a pixel has the same distance to\n",
    "    multiple regions, as it is not defined which region expands into that\n",
    "    space. Here, the exact behavior depends on the upstream implementation\n",
    "    of ``scipy.ndimage.distance_transform_edt``.\n",
    "    See Also\n",
    "    --------\n",
    "    :func:`skimage.measure.label`, :func:`skimage.segmentation.watershed`, :func:`skimage.morphology.dilation`\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] https://cellprofiler.org\n",
    "    .. [2] https://github.com/CellProfiler/CellProfiler/blob/082930ea95add7b72243a4fa3d39ae5145995e9c/cellprofiler/modules/identifysecondaryobjects.py#L559\n",
    "    Examples\n",
    "    --------\n",
    "    >>> labels = np.array([0, 1, 0, 0, 0, 0, 2])\n",
    "    >>> expand_labels(labels, distance=1)\n",
    "    array([1, 1, 1, 0, 0, 2, 2])\n",
    "    Labels will not overwrite each other:\n",
    "    >>> expand_labels(labels, distance=3)\n",
    "    array([1, 1, 1, 1, 2, 2, 2])\n",
    "    In case of ties, behavior is undefined, but currently resolves to the\n",
    "    label closest to ``(0,) * ndim`` in lexicographical order.\n",
    "    >>> labels_tied = np.array([0, 1, 0, 2, 0])\n",
    "    >>> expand_labels(labels_tied, 1)\n",
    "    array([1, 1, 1, 2, 2])\n",
    "    >>> labels2d = np.array(\n",
    "    ...     [[0, 1, 0, 0],\n",
    "    ...      [2, 0, 0, 0],\n",
    "    ...      [0, 3, 0, 0]]\n",
    "    ... )\n",
    "    >>> expand_labels(labels2d, 1)\n",
    "    array([[2, 1, 1, 0],\n",
    "           [2, 2, 0, 0],\n",
    "           [2, 3, 3, 0]])\n",
    "    \"\"\"\n",
    "\n",
    "    distances, nearest_label_coords = distance_transform_edt(\n",
    "        label_image == 0, return_indices=True\n",
    "    )\n",
    "    labels_out = np.zeros_like(label_image)\n",
    "    dilate_mask = distances <= distance\n",
    "    # build the coordinates to find nearest labels,\n",
    "    # in contrast to [1] this implementation supports label arrays\n",
    "    # of any dimension\n",
    "    masked_nearest_label_coords = [\n",
    "        dimension_indices[dilate_mask]\n",
    "        for dimension_indices in nearest_label_coords\n",
    "    ]\n",
    "    nearest_labels = label_image[tuple(masked_nearest_label_coords)]\n",
    "    labels_out[dilate_mask] = nearest_labels\n",
    "    return labels_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Explanation of how function 'remove_disconnected_objects' works: \n",
    "###### label = 10336\n",
    "###### object_i output (correspond to the minimal parallelepiped that contains the object):\n",
    "###### [[10336 10336 13346 13346 13346 13346 13346]\n",
    "###### [    0     0 13346 13346 13346 13346 13346]\n",
    "###### [    0     0 13346 13346 13346 13346 13346]\n",
    "###### [    0 15317 10336 13346 13346 13346 10336]\n",
    "###### [15317 15317 15317 15317 13346 10336     0]]\n",
    "\n",
    "###### object_i== label: \n",
    "###### [[ True  True False False False False False]\n",
    "######  [False False False False False False False]\n",
    "###### [False False False False False False False]\n",
    "###### [False False  True False False False  True]\n",
    "###### [False False False False False  True False]]\n",
    "###### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_disconnected_objects(mask_2D, min_size, pxl_connect):      \n",
    "    \"\"\"Remove small objects that are disconnected on a 2D plane, but merge on a next plane.\n",
    "    The function takes each object seperately on an image and removes smaller parts of the object\n",
    "    and leaves the biggest part of the object intact. pxl_connect specifies the connectivity to find neigbours, and \n",
    "    min_size specifies the size of the object that should always be removed.\"\"\"\n",
    "    \n",
    "    all_objects = ndi.find_objects(mask_2D)\n",
    "\n",
    "    for i, sl in enumerate(all_objects):\n",
    "        if sl is None:\n",
    "            continue\n",
    "\n",
    "        label_id = i + 1\n",
    "\n",
    "        object_i = mask_2D[sl] #matrix of the area where object is present\n",
    "\n",
    "        boolean_object_i = object_i== label_id\n",
    "        boolean_object_i = boolean_object_i.astype(int)\n",
    "        labeled_ob_i = label(boolean_object_i,connectivity=pxl_connect)\n",
    "        object_sizes = np.bincount(labeled_ob_i.ravel())\n",
    "\n",
    "        #following steps modified from skimage.measure.remove_small_objects\n",
    "        #do not modify object if only one present:\n",
    "        if len(object_sizes) <= 2:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            too_small = object_sizes <= min_size\n",
    "\n",
    "            if sum(too_small) >= 1:\n",
    "                too_small_mask = too_small[labeled_ob_i]        \n",
    "                object_i[too_small_mask] = 0\n",
    "\n",
    "            #find max and min size in the np array, ignore the first element as this is for count==0\n",
    "            #uncomment to check the size of disconnected objects\n",
    "            ####print(object_sizes)\n",
    "            max_ob = object_sizes[1:].max()\n",
    "\n",
    "            the_biggest = object_sizes < max_ob        \n",
    "            the_biggest_mask = the_biggest[labeled_ob_i]        \n",
    "            object_i[the_biggest_mask] = 0\n",
    "            mask_2D[sl] = object_i\n",
    "\n",
    "    return mask_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function from skimage package https://github.com/scikit-image/scikit-image/blob/main/skimage/measure/_regionprops.py#L869-L1161\n",
    "\n",
    "COL_DTYPES = {\n",
    "    'area': int,\n",
    "    'bbox': int,\n",
    "    'bbox_area': int,\n",
    "    'moments_central': float,\n",
    "    'centroid': float,\n",
    "    'convex_area': int,\n",
    "    'convex_image': object,\n",
    "    'coords': object,\n",
    "    'eccentricity': float,\n",
    "    'equivalent_diameter': float,\n",
    "    'euler_number': int,\n",
    "    'extent': float,\n",
    "    'feret_diameter_max': float,\n",
    "    'filled_area': int,\n",
    "    'filled_image': object,\n",
    "    'moments_hu': float,\n",
    "    'image': object,\n",
    "    'inertia_tensor': float,\n",
    "    'inertia_tensor_eigvals': float,\n",
    "    'intensity_image': object,\n",
    "    'label': int,\n",
    "    'local_centroid': float,\n",
    "    'major_axis_length': float,\n",
    "    'max_intensity': int,\n",
    "    'mean_intensity': float,\n",
    "    'min_intensity': int,\n",
    "    'minor_axis_length': float,\n",
    "    'moments': float,\n",
    "    'moments_normalized': float,\n",
    "    'orientation': float,\n",
    "    'perimeter': float,\n",
    "    'slice': object,\n",
    "    'solidity': float,\n",
    "    'weighted_moments_central': float,\n",
    "    'weighted_centroid': float,\n",
    "    'weighted_moments_hu': float,\n",
    "    'weighted_local_centroid': float,\n",
    "    'weighted_moments': float,\n",
    "    'weighted_moments_normalized': float\n",
    "}\n",
    "\n",
    "OBJECT_COLUMNS = {\n",
    "    'image', 'coords', 'convex_image', 'slice',\n",
    "    'filled_image', 'intensity_image'\n",
    "}\n",
    "\n",
    "def  skimage_props_to_dict(regions, properties=('label', 'bbox'), separator='-'):\n",
    "    \"\"\"Convert image region properties list into a column dictionary.\"\"\"\n",
    "\n",
    "    out = {}\n",
    "    n = len(regions)\n",
    "    for prop in properties:\n",
    "        r = regions[0]\n",
    "        rp = getattr(r, prop)\n",
    "        if prop in COL_DTYPES:\n",
    "            dtype = COL_DTYPES[prop]\n",
    "        else:\n",
    "            func = r._extra_properties[prop]\n",
    "            dtype = _infer_regionprop_dtype(\n",
    "                func,\n",
    "                intensity=r._intensity_image is not None,\n",
    "                ndim=r.image.ndim,\n",
    "            )\n",
    "        column_buffer = np.zeros(n, dtype=dtype)\n",
    "\n",
    "        # scalars and objects are dedicated one column per prop\n",
    "        # array properties are raveled into multiple columns\n",
    "        # for more info, refer to notes 1\n",
    "        if np.isscalar(rp) or prop in OBJECT_COLUMNS or dtype is np.object_:\n",
    "            for i in range(n):\n",
    "                column_buffer[i] = regions[i][prop]\n",
    "            out[prop] = np.copy(column_buffer)\n",
    "        else:\n",
    "            if isinstance(rp, np.ndarray):\n",
    "                shape = rp.shape\n",
    "            else:\n",
    "                shape = (len(rp),)\n",
    "\n",
    "            for ind in np.ndindex(shape):\n",
    "                for k in range(n):\n",
    "                    loc = ind if len(ind) > 1 else ind[0]\n",
    "                    column_buffer[k] = regions[k][prop][loc]\n",
    "                modified_prop = separator.join(map(str, (prop,) + ind))\n",
    "                out[modified_prop] = np.copy(column_buffer)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_stack_for_napari(channel_name_to_load, base_folder, missing, crop_im = True):\n",
    "    metal_folder = base_folder +\"/\" + channel_name_to_load\n",
    "    image_path1 = image_filepath_for_3D_stack(metal_folder)\n",
    "    image1 = imread(image_path1, pattern = None)\n",
    "    \n",
    "    if missing is not None:\n",
    "        missing_slice_image = np.mean( np.array([image1[missing-1, :,:],image1[missing+1,:,:]]), axis=0)\n",
    "        image1 =  np.insert(image1,missing, missing_slice_image, axis=0)\n",
    "    \n",
    "    for i in range(image1.shape[0]):\n",
    "        #percent99 = np.percentile(image1[i, :,:], 99)\n",
    "        #tmp_im = np.clip(image1[i, :,:],0,percent99)\n",
    "        tmp_im = cv2.normalize(image1[i, :,:], None, alpha=0, beta=65535, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_16U)\n",
    "        tmp_im = np.clip(tmp_im,0,65535)\n",
    "        image1[i, :,:] = cv2.GaussianBlur(tmp_im,(3,3),1)\n",
    "        #image1[i, :,:] = cv2.blur(tmp_im,(3,3))\n",
    "               \n",
    "    if crop_im == True:\n",
    "         image1 = image1[:, y_start:y_end,x_start:x_end]\n",
    "     \n",
    "    print('Max pixel value:', np.max(image1))\n",
    "    print('Median pixel value:', np.percentile(image1, 50))\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#follwing funtions from https://github.com/BodenmillerGroup/ImcPluginsCP/blob/d14624f2f47bd0c745b5b4345d440d8cc103b563/plugins/correctspillovermeasurements.py\n",
    "import scipy.optimize as spo\n",
    "def compensate_ls(dat, sm):\n",
    "    compdat = np.linalg.lstsq(sm.T, dat.T, None)[0]\n",
    "    return compdat.T\n",
    "\n",
    "def compensate_nnls(dat, sm):\n",
    "    def nnls(x):\n",
    "        return spo.nnls(sm.T, x)[0]\n",
    "\n",
    "    return np.apply_along_axis(nnls, 1, dat)\n",
    "\n",
    "def compensate_dat( dat, sm, method):\n",
    "    \"\"\"\n",
    "    Compensate by solving the linear system:\n",
    "        comp * sm = dat -> comp = dat * inv(sm)\n",
    "    \"\"\"\n",
    "    # only compensate cells with all finite measurements\n",
    "    fil = np.all(np.isfinite(dat), 1)\n",
    "    \n",
    "    if np.sum(fil) == 0:\n",
    "        # Dont compensate if there are now valid rows!\n",
    "        return dat\n",
    "    compdat = dat.copy()\n",
    "    \n",
    "    if method == 'METHOD_LS':\n",
    "        compdat[fil, :] = compensate_ls(dat[fil, :], sm)\n",
    "    \n",
    "    if method == 'METHOD_NNLS':\n",
    "        compdat[fil, :] = compensate_nnls(dat[fil, :], sm)\n",
    "    # columns with any not finite value are set to np.nan\n",
    "    compdat[~fil, :] = np.nan\n",
    "    \n",
    "    return compdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function thaken from https://github.com/BodenmillerGroup/ImcPluginsCP/blob/master/plugins/smoothmultichannel.py\n",
    "def clip_hot_pixels(img, hp_filter_shape, hp_threshold):\n",
    "    if hp_filter_shape[0] % 2 != 1 or hp_filter_shape[1] % 2 != 1:\n",
    "        raise ValueError(\n",
    "            \"Invalid hot pixel filter shape: %s\" % str(hp_filter_shape)\n",
    "        )\n",
    "    hp_filter_footprint = np.ones(hp_filter_shape)\n",
    "    hp_filter_footprint[\n",
    "        int(hp_filter_shape[0] / 2), int(hp_filter_shape[1] / 2)\n",
    "    ] = 0\n",
    "    max_img = ndi.maximum_filter(\n",
    "        img, footprint=hp_filter_footprint, mode=\"reflect\"\n",
    "    )\n",
    "    hp_mask = img - max_img > hp_threshold\n",
    "    img = img.copy()\n",
    "    img[hp_mask] = max_img[hp_mask]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: single chanel TIFFs from the whole 3D model to use for \n",
    "\n",
    "#folder for registeration i.e an image per slice\n",
    "input_base = '~/3D_model201710/3D_registred_tiffs/IMC_fullStack_registred/imageJ_registration/full_model_aligned/'\n",
    "\n",
    "\n",
    "#INPUT: stack of single channel tiffs for each slice for each metal channel to whcih \n",
    "#the transformation will be applied. Tiffs for each slice are separated into folders.\n",
    "stack_registred = input_base + 'SIMILARITY10_Nd148'\n",
    "labels_name = 'segmentation_hwatershed_500.00_90%.tif'\n",
    "initial_labels = input_base + labels_name\n",
    "\n",
    "\n",
    "#overlapping area of the image stack ie the area for the full 3D model used for downstream data analysis. \n",
    "row_start = 448 #y\n",
    "row_end = 936 #y\n",
    "col_start = 386 #x\n",
    "col_end = 1038 #x\n",
    "\n",
    "#replace metal names with target names for downstream analysis\n",
    "#csv panel to replace metal names with the antibody target \n",
    "csv_pannel = \"~/model201710_panel.csv\"\n",
    "csv_pannel_new_name = 'clean_target'\n",
    "csv_pannel_metal = 'Metal Tag'\n",
    "\n",
    "\n",
    "#also measure volume for each object \n",
    "properties_to_measure_for_metals = ['mean_intensity'] #regionprops uses enumarate thus objects always retriewed in numrical ascending order\n",
    "additional_properties_to_measure = ('label', 'area')\n",
    "\n",
    "#data type for intensities to measure\n",
    "dtype_to_measure = np.uint16\n",
    "\n",
    "#remove channels not used for downstream data analysis\n",
    "channels_not_to_include = ['Y89','Ru96','Ru98','Ru99','Ru100', 'Ru101', 'Ru102', 'Ru104', 'Ir191','In115', \n",
    "                           'La139','Nd145', 'Gd155', 'Gd158','Dy163','Er170','Eu151', 'Sm154', 'Er166', 'Tm169', 'Dy161']\n",
    "\n",
    "new_lables_name = 'final' + '_' + labels_name\n",
    "measured_mask_name = 'measured_mask' + '_' + new_lables_name\n",
    "#depends on number of objects found in the segmentation output\n",
    "dtype_for_cell_labels = 'uint32'\n",
    "#output tabel names\n",
    "intensities_table_name = input_base + 'model201710_mean_intensities.csv'\n",
    "extra_properties_table_name = input_base + 'model201710_labels_area.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Load a nuclear and cytoplasmic channel and the segmentation mask. Remove objects in 3D that are less than 10 pixels in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1= 'Ir191'\n",
    "ir_im_stack = load_channel_stack_for_napari(channel_1,stack_registred, None,False )\n",
    "\n",
    "channel_2 = 'Pr141'\n",
    "cyto_im_stack  = load_channel_stack_for_napari(channel_2,stack_registred, None,False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_im_stack_ini = imread(initial_labels, pattern = None)\n",
    "napari_name_seg = 'segmentation'\n",
    "\n",
    "mask_im_stack = np.zeros((round(mask_im_stack_ini.shape[1]/2),mask_im_stack_ini.shape[2],mask_im_stack_ini.shape[3] ))\n",
    "mask_im_stack = mask_im_stack.astype(dtype_for_cell_labels)\n",
    "\n",
    "\n",
    "for i in range(mask_im_stack.shape[0]):\n",
    "    if i ==0 :\n",
    "        mask_im_stack[i, :, :] = mask_im_stack_ini[:,i, :, :]\n",
    "    else:\n",
    "        mask_im_stack[i, :, :] = mask_im_stack_ini[:,i*2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_im_stack_ini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_removed = remove_small_objects(mask_im_stack, min_size=11, connectivity=1) #min size < x, not <="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Remove small disconnected objects and small objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_mask = np.zeros(mask_im_stack.shape, dtype = mask_im_stack.dtype)\n",
    "k = 0 \n",
    "while k < small_removed.shape[0]: \n",
    "    slice_2D = small_removed[k, :,:]\n",
    "    disconnect_removed = remove_small_disconnected_objects(slice_2D, min_size = 7, pxl_connect = 1) #here min size <= nr\n",
    "    small_slice_removed = remove_small_objects(disconnect_removed, min_size =4,connectivity=1) #here min size < nr\n",
    "    improved_mask[k,:,:] = expand_labels(small_slice_removed , 1)\n",
    "    k  = k + 1\n",
    "\n",
    "improved_mask = remove_small_objects(improved_mask , min_size=21, connectivity=1) #min size < x, not <=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove objects with idirium raw signal less than 1\n",
    "object_prop_dict =dict()\n",
    "channels_to_include = 'Ir191'\n",
    "\n",
    "for file_name in os.listdir(stack_registred):\n",
    "    \n",
    "    if file_name in channels_to_include:\n",
    "        im_files = os.path.join(stack_registred , file_name)    \n",
    "        img_list = image_filepath_for_3D_stack(im_files)\n",
    "        metal_im = imread(img_list, pattern=None)\n",
    "        metal_im = np.array(metal_im, dtype=dtype_to_measure)\n",
    "        metal_im = np.clip(metal_im, 0,np.percentile(metal_im, 99))\n",
    "        #warning regionprops used enumerate() to retriev objects. Thus I assume that the order of objects retreived is always the same. Should be checked \n",
    "        # if code is modified. Can be checked inside of this function by including 'label' again for properties_to_measure_for_metals\n",
    "        object_prop=regionprops(improved_mask,intensity_image= metal_im)\n",
    "        out_dict = dict()\n",
    "        out_dict = skimage_props_to_dict(object_prop, properties=properties_to_measure_for_metals)\n",
    "        for prop_to_measure in properties_to_measure_for_metals: \n",
    "            new_key =  file_name + '_' + prop_to_measure\n",
    "            out_dict[new_key] = out_dict.pop(prop_to_measure)\n",
    "\n",
    "        object_prop_dict.update(out_dict)\n",
    "        \n",
    "props_table =pd.DataFrame()\n",
    "props_table = pd.DataFrame(object_prop_dict)\n",
    "object_dict = pd.DataFrame.to_dict(props_table)\n",
    "\n",
    "low_iridium_signal_objects = []\n",
    "for obi in object_dict['Ir191_mean_intensity'].keys():\n",
    "    ir = object_dict['Ir191_mean_intensity'][obi]\n",
    "    if ir < 1:\n",
    "        low_iridium_signal_objects.append(obi)\n",
    "\n",
    "updated_mask = copy.deepcopy(improved_mask)\n",
    "for item in range(len(low_iridium_signal_objects)):\n",
    "    obi = int(low_iridium_signal_objects[item])\n",
    "    updated_mask[improved_mask == obi] = 0\n",
    "\n",
    "new_lables_name = input_base + new_lables_name\n",
    "imsave(new_lables_name, updated_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors = [2,1,1]\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.view_image(ir_im_stack[:,row_start:row_end,col_start:col_end], name = channel_1, scale = scaling_factors)\n",
    "    viewer.add_image(cyto_im_stack[:,row_start:row_end,col_start:col_end], name = channel_2, scale = scaling_factors)\n",
    "    viewer.add_labels(updated_mask[:,row_start:row_end,col_start:col_end], name = napari_name_seg,scale = scaling_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Measure intensities for all channels in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: this measures only the intensities for objects in the overlapping area\n",
    "mask_to_measure = updated_mask[:,row_start:row_end,col_start:col_end]\n",
    "\n",
    "mask_to_measure = remove_small_objects(mask_to_measure , min_size=21, connectivity=1) #min size < x, not <=\n",
    "\n",
    "mask_to_measure_name = input_base + measured_mask_name\n",
    "imsave(mask_to_measure_name, mask_to_measure)\n",
    "\n",
    "object_prop_dict =dict()\n",
    "\n",
    "for file_name in os.listdir(stack_registred):\n",
    "    \n",
    "    if file_name in channels_not_to_include:\n",
    "        continue\n",
    "    else:\n",
    "        im_files = os.path.join(stack_registred , file_name)    \n",
    "        img_list = image_filepath_for_3D_stack(im_files)\n",
    "        metal_im = imread(img_list, pattern=None)\n",
    "        metal_im = np.array(metal_im, dtype=dtype_to_measure)\n",
    "        metal_im = metal_im[:,row_start:row_end,col_start:col_end]\n",
    "        metal_im_smoothed = np.zeros(metal_im.shape)\n",
    "        for layer in range(metal_im.shape[0]):\n",
    "            one_im = metal_im[layer, :, :]\n",
    "            smoothed_im = clip_hot_pixels(one_im, [3,3], 50)\n",
    "            metal_im_smoothed[layer] = smoothed_im\n",
    "        #warning regionprops used enumerate() to retriev objects. Thus I assume that the order of objects retreived is always the same. Should be checked \n",
    "        # if code is modified. Can be checked inside of this function by including 'label' again for properties_to_measure_for_metals\n",
    "        object_prop=regionprops(mask_to_measure,intensity_image= metal_im)\n",
    "        out_dict = dict()\n",
    "        out_dict = skimage_props_to_dict(object_prop, properties=properties_to_measure_for_metals)\n",
    "        for prop_to_measure in properties_to_measure_for_metals: \n",
    "            new_key =  file_name + '_' + prop_to_measure\n",
    "            out_dict[new_key] = out_dict.pop(prop_to_measure)\n",
    "\n",
    "        object_prop_dict.update(out_dict)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "with open(csv_pannel, 'r') as NN:            \n",
    "    reader = csv.DictReader(NN)\n",
    "    for row in reader:\n",
    "        names[row[csv_pannel_metal]] = row[csv_pannel_new_name]\n",
    "\n",
    "entries = list(object_prop_dict.keys())\n",
    "updated_measures = object_prop_dict\n",
    "\n",
    "#entries = object_prop_dict.keys()\n",
    "for entry in entries:\n",
    "    if '_mean_' in entry:\n",
    "        entry_new = entry[:-15]\n",
    "        updated_measures[entry_new] = updated_measures.pop(entry)\n",
    "        updated_measures.update(updated_measures)\n",
    "\n",
    "        \n",
    "props_table =pd.DataFrame()\n",
    "props_table = pd.DataFrame(updated_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_comp_matrix = '~/compensationMatrix.csv'\n",
    "compensation_matrix = pd.read_csv(ori_comp_matrix,index_col=0)\n",
    "\n",
    "metals_not_in_cm = []\n",
    "for metal in compensation_matrix.columns.values:\n",
    "    if metal not in props_table.columns.values:\n",
    "        metals_not_in_cm.append(metal)\n",
    "compensation_matrix_new = compensation_matrix.drop(columns=metals_not_in_cm)\n",
    "compensation_matrix_new = compensation_matrix_new.drop(metals_not_in_cm)\n",
    "\n",
    "metals_not_in_data = []\n",
    "\n",
    "for metal in props_table.columns.values:\n",
    "    if metal not in compensation_matrix.columns.values:\n",
    "        metals_not_in_data.append(metal)\n",
    "\n",
    "for metal in metals_not_in_data:\n",
    "    compensation_matrix_new[metal] = 0\n",
    "    \n",
    "cm = np.asarray(compensation_matrix_new.values)\n",
    "diagonal_ones = np.identity(len(metals_not_in_data))\n",
    "added_rows = np.zeros((cm.shape[1]-cm.shape[0],cm.shape[0]),dtype=int)\n",
    "rows_final = np.concatenate((added_rows, diagonal_ones), axis =1)\n",
    "cm_final = np.concatenate((cm, rows_final), axis =0)\n",
    "\n",
    "new_order = compensation_matrix_new.columns.values\n",
    "props_table_ordered = props_table[new_order]\n",
    "uncompensated_data = props_table_ordered.values\n",
    "comp_data = compensate_dat( uncompensated_data, cm_final, 'METHOD_NNLS')\n",
    "\n",
    "props_table_compensated = pd.DataFrame(comp_data, columns = props_table_ordered.columns.values)\n",
    "props_table_compensated =props_table_compensated.rename(columns = names)\n",
    "props_table_compensated.to_csv(intensities_table_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_additional_prop=regionprops_table(mask_to_measure, properties= additional_properties_to_measure)\n",
    "props_table = pd.DataFrame(object_additional_prop)\n",
    "props_table.to_csv(extra_properties_table_name, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure major and minor axis of each object in xy and z direction to establish if segmentation is biased in x-y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_diameter_dict =dict()\n",
    "objects_to_measure = copy.deepcopy(mask_to_measure)\n",
    "objects_to_measure = clear_border(objects_to_measure)\n",
    "\n",
    "stack_max = max(range(objects_to_measure.shape[0]))\n",
    "\n",
    "for x in range(stack_max+1):\n",
    "    if x ==0 or x == stack_max:\n",
    "        continue\n",
    "    object_diameter_2d_xy=regionprops(objects_to_measure[x,:,:])\n",
    "    out_dict = dict()\n",
    "    out_dict = skimage_props_to_dict(object_diameter_2d_xy, properties=['label','minor_axis_length', 'major_axis_length'])\n",
    "    diameter_list_minor = out_dict['minor_axis_length']\n",
    "    diameter_list_major = out_dict['major_axis_length']\n",
    "    \n",
    "    diameter_keys = out_dict['label']\n",
    "    \n",
    "    for i in range(len(diameter_list_major)):\n",
    "        minor = diameter_list_minor[i]\n",
    "        major = diameter_list_major[i]\n",
    "        \n",
    "        if minor == 'NaN':\n",
    "            minor = 0\n",
    "            \n",
    "        if major == 'NaN':\n",
    "            major = 0\n",
    "            \n",
    "        average_axis = (minor + major)/2  \n",
    "        \n",
    "        obi_key = diameter_keys[i]\n",
    "       \n",
    "        if  obi_key not in object_diameter_dict.keys():            \n",
    "            object_diameter_dict[obi_key] = average_axis \n",
    "        else:\n",
    "            current_diameter = object_diameter_dict[obi_key]            \n",
    "            if current_diameter < average_axis:\n",
    "                object_diameter_dict[obi_key] = average_axis\n",
    "                \n",
    "                               \n",
    "diameter_table = pd.DataFrame.from_dict(object_diameter_dict, 'index', columns= ['average_axis_xy'])\n",
    "diameter_table = diameter_table.reset_index()\n",
    "diameter_table =diameter_table.rename(columns = {'index': 'label', 'average_axis_xy': 'average_axis_xy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_props_table = pd.merge(props_table, diameter_table, how='left', on='label', left_on=None, right_on=None,left_index=False, right_index=False, sort=True,\n",
    "      suffixes=('_x', '_y'), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_shape = mask_to_measure.shape\n",
    "\n",
    "double_stack = np.zeros((image1_shape[0]*2-1, image1_shape[1], image1_shape[2]), dtype = mask_im_stack.dtype)\n",
    "\n",
    "k = 0\n",
    "for i in range(image1_shape[0]-1):\n",
    "    if i == 0 :\n",
    "        double_stack[i,:,:] = mask_to_measure[k, :,:]\n",
    "        double_stack[i+1,:,:] = mask_to_measure[k, :,:]\n",
    "\n",
    "    else:\n",
    "        double_stack[i*2,:,:] = mask_to_measure[k, :,:]\n",
    "        double_stack[i*2+1,:,:] = mask_to_measure[k, :,:]\n",
    "\n",
    "    k = k+1\n",
    "\n",
    "double_stack[k*2,:,:] = mask_to_measure[k, :,:]\n",
    "    \n",
    "axis_changed_lables = copy.deepcopy(double_stack)\n",
    "axis_changed_lables = np.swapaxes(axis_changed_lables,0,1)\n",
    "axis_changed_lables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_diameter_dict =dict()\n",
    "axis_changed_lables = clear_border(axis_changed_lables)\n",
    "\n",
    "stack_max = max(range(axis_changed_lables.shape[0]))\n",
    "for x in range(stack_max+1):\n",
    "    if x ==0 or x == stack_max:\n",
    "        continue\n",
    "        \n",
    "    object_diameter_2d_xy=regionprops(axis_changed_lables[x,:,:])\n",
    "    out_dict = dict()\n",
    "    out_dict = skimage_props_to_dict(object_diameter_2d_xy, properties=['label','minor_axis_length', 'major_axis_length'])\n",
    "    diameter_list_minor = out_dict['minor_axis_length']\n",
    "    diameter_list_major = out_dict['major_axis_length']\n",
    "    \n",
    "    diameter_keys = out_dict['label']\n",
    "    \n",
    "    for i in range(len(diameter_list_major)):\n",
    "        minor = diameter_list_minor[i]\n",
    "        major = diameter_list_major[i]\n",
    "        \n",
    "        if minor == 'NaN':\n",
    "            minor = 0\n",
    "            \n",
    "        if major == 'NaN':\n",
    "            major = 0\n",
    "            \n",
    "        average_axis = (minor + major)/2  \n",
    "        \n",
    "        obi_key = diameter_keys[i]\n",
    "       \n",
    "        if  obi_key not in object_diameter_dict.keys():            \n",
    "            object_diameter_dict[obi_key] = average_axis \n",
    "        else:\n",
    "            current_diameter = object_diameter_dict[obi_key]            \n",
    "            if current_diameter < average_axis:\n",
    "                object_diameter_dict[obi_key] = average_axis                    \n",
    "                    \n",
    "diameter_table = pd.DataFrame.from_dict(object_diameter_dict, 'index', columns= ['average_axis_z'])\n",
    "diameter_table = diameter_table.reset_index()\n",
    "diameter_table =diameter_table.rename(columns = {'index': 'label', 'average_axis_z': 'average_axis_z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_extra_props = pd.merge(extra_props_table, diameter_table, how='left', on='label', left_on=None, right_on=None,left_index=False, right_index=False, sort=True,\n",
    "      suffixes=('_x', '_y'), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter =final_extra_props.plot.scatter(x = 'average_axis_xy', y = 'average_axis_z',s = 0.4, c = 'DarkGray')\n",
    "fig_scatter.set_xlim([0,18])\n",
    "fig_scatter.set_ylim([0,18])\n",
    "s = pd.Series([0,1,2,3,4,5,6,7,8,9,10,11, 12, 13, 14, 15, 16, 17, 18, ])\n",
    "\n",
    "s.plot.line(color= 'black', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fig_scatter.get_figure()\n",
    "fig.savefig('~/figures/xy_vs_z_average_axis_model201710.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
